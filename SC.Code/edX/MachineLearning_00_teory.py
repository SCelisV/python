# MachineLearning_00_teory.py
# MachineLearning_00_code.py

# MÃ³delos predictivos con Machine Learning - MPML - SCProjects/0_SCProjects_github.com_SCelisV/python/SC.Code/jupyter/MPML
# Machine Learning (intro prÃ¡ctica) - ML - SCProjects/0_SCProjects_github.com_SCelisV/python/SC.Code/edX/Machine_Learning
# Python Basics for Data Science PBfDS - SCProjects/0_SCProjects_github.com_SCelisV/python/SC.Code/edX/Python_Basics_for_Data_Science

""" 
.-. Machine Learning 

Es el subcampo de la ciencia de la computaciÃ³n que "da a las computadoras la habilidad de aprender sin ser programadas explicitamente".

Es decir, reconocer y diferenciar los datos en un conjunto de caracteristicas detalladas, de tal forma que al escribir algunas reglas Ã³ mÃ©todos para que las computadoras sean "inteligentes" y puedan representar ese conjunto de datos de forma generalizada e incluso permita detectar casos nuevos construyendo un modelo que sea capaz de observar todos los conjuntos de caracteristicas, y su correspondiente tipo y aprender el patron de cada uno. (entender y diferenciar), de tal forma que aprendan de ellos mismos y encuentren informaciÃ³n oculta.

Se utiliza en muchos campos de la industria, 
- Salud (cancer), Ã¡rboles de decisiÃ³n que ayudan a prescribir la medicina de sus pacientes, partiendo de sus datos histÃ³ricos.
- Finanzas, aprobaciÃ³n Ã³ no de operaciones, segmentaciÃ³n de clientes, predecir la probabilidad de impago para cada solicitante, predecir el comportamiento de sus clientes, (abandono Ã³ fidelidad)..etc.
- Entretenimiento, You Tube, Amazon, NetFlix utilizan modelos de RecomendaciÃ³n para producir sugerencias que el usuario pueda disfrutar.
- Chatbots, juegos de ordenador, reconocimiento facial, acceso a los moviles. 
- Cancer detection, Predicting economic trends, Predicting customer churn, Recomendations engines


Techniques ML - TÃ©cnicas de Machine Learning - Machine learning techniques.
===========================================================================

    Regression/Estimation - Predicting continuos value - Predecir un valor continuo.
    Predecir un valor numÃ©rico (continuo), tenemos un problema de regresiÃ³n.
    AproximaciÃ³n que modela una relaciÃ³n entre una variable escalar dependiente ("Y") y una o mÃ¡s variables explicativas ("X")
    DibujarÃ¡ una recta que nos indicarÃ¡ la tendencia del conjunto de datos.
    Nos ayudarÃ¡ a predecir en funciÃ³n de un valor X un valor Y.

    Classification - Predicting the item class/category or case.
    Predecir una clase (Ã³ categorÃ­a), tenemos un problema de clasificaciÃ³n.
Applications: Spam detection, image recognition.
    una celula es Maligna Ã³ Benigna
    un cliente se va a retirar Ã³ no
Algorithms: 


    Clustering - Finding the structure of data; summarization
    Separar los datos en diferentes grupos (de casos similares), tenemos un problema de agrupamiento.
Applications: Customer segmentation, Grouping experiment outcomes
    los grupos de casos similares
    pacientes similares
    segmentaciÃ³n de clientes en el campo bancario
Algorithms: k-Means, spectral clustering, mean-shift,


    Associations - Associating frequent co-occurring item/events
    Predecir Ã³ buscar elementos Ã³ sucesos que a menudo se producen conjuntamente, tenemos un problema de asociaciÃ³n.
    Buscar elementos o sucesos que a menudo se producen conjuntamente
Applications: ArtÃ­culos comestibles que normalmente son comprados conjuntamente por un cliente en particular.
Algorithms: 


    Anomaly detection - Discovering abnormal and unusual cases.
    DetecciÃ³n de anomalias, se utiliza para descubrir casos anormales e inusuales, por ejemplo, detecciÃ³n del fraude en tarjetas de crÃ©dito.

Applications: DetecciÃ³n de fraude de tarjetas de crÃ©dito
Algorithms: 


    Dimension Reduction - Reducing the size of data (PCA)
    Si queremos simplificar la informaciÃ³n, tenemos un problema de reducciÃ³n de dimensiones (reducir la dimensiÃ³n del problema), reducir el tamaÃ±o de los datos.
Applications: ArtÃ­culos comestibles que normalmente son comprados conjuntamente por un cliente en particular.
Algorithms: 
 

    Recommendation systems - Recommendation items
    AsociaciÃ³n de las preferencias de la gente con otros de gustos similares,  y recomendaciÃ³n de nuevos articulos como libros y pelÃ­culas.
Applications: ArtÃ­culos comestibles que normalmente son comprados conjuntamente por un cliente en particular.
Algorithms: 


    Sequence mining - Predicting next events; click-stream (Markov Model, HMM)
    Se utiliza para predecir el siguiente evento, (pulsaciÃ³n en un website)
Applications: secuencia de pulsaciÃ³n del usuario en sitios web
Algorithms: 



Artificial Intelligent vs Machine Learning vs Deep Learning
-----------------------------------------------------------

AI trata de hacer las computadoras inteligentes para imitar las funciones cognitivas de los seres humanos
AI componentes:
    - computer vision
    - language processing
    - creativity and summarization

Rama de la IA que cubre la parte estadÃ­stica de la IA.
EnseÃ±a a la computadora a resolver problemas al mirar cientos Ã³ miles de ejemplos.
Aprender de ellos y usar esa experiencia para resolver el mismo problema en nuevas situaciones.
Machine learning:
    - classification
    - clustering
    - neural network

Campo especial de ML donde las computadoras pueden aprender y tomar decisiones inteligentes por su cuenta.
Involucra un nivel mÃ¡s profundo de automatizaciÃ³n en comparaciÃ³n con la mayorÃ­a de los algoritmos de ML.
Revolution in ML:
    - deep learning
dada

# Tipos de aprendizaje => Algoritmos => Supervisado, NO Supervisado, De Refuerzo

.-. Aprendizaje supervisado => LABELED DATA

"Teach the model", with that knowledge, it can predict unknown or future instances.
Observar y dirigir la ejecuciÃ³n de una tarea, proyecto o actividad.
SupervisiÃ³n de modelos de ML que sean capace de producir regiones de clasificaciÃ³n..etc.
Educamos un modelo entrenandolo con algunos datos de un conjunto de datos (conocidos) y etiquetados, (identifican los atributos).
Al graficar una fila o observaciÃ³n del dataSet sÃ³lo veremos un punto en el grÃ¡fico.
DataSet normalmente tiene Datos nÃºmeric and categoric(for clasification).

Necesita datos previamente etiquetados(lo que es correcto y lo que no es correcto) para aprender a realizar el trabajo. 
En base a esto, el algoritmo aprenderÃ¡ a resolver problemas futuros similares.
Los algoritmos de aprendizaje supervisado son aquellos que trabajan primeramente aprendiendo con un conjunto de datos de entrenamiento "etiquetados", los cuales recibe para posteriormente trabajar con ellos, intentando asignarles correctamente una etiqueta que coincida con la que previamente tenÃ­a.

El comportamiento del algoritmo se corrige en medida a cuÃ¡ntas veces fallo al momento de etiquetar los datos de prueba y posteriormente modifica su comportamiento para las prÃ³ximas ejecuciones. 

DespuÃ©s de terminar de entrenar con los datos etiquetados, se somete al algoritmo a trabajar con un conjunto de datos nuevos para los que no se conoce la etiqueta. 

.-. Classification.-. is the process of predicting discrete class labels or categories.
.-. Regression.-. is the process of predictin continuos values.

.-. Aprendizaje NO supervisado =>  UNLABELED DATA

Unsupervised learning, The model works on its own to discover information.
Dejamos que el algoritmo trabaje por su cuenta para descubir informaciÃ³n que puede ser invisible para el ojo humano.
Se entrenan con el conjunto de datos y extrae conclusiones sobre datos sin etiquetar.
Tenemos poco o nada acerca de los datos o los resultados que esperan.
Los algoritmos de aprendizaje no supervisado no cuentan con un conjunto de datos "etiquetados" con los cuales puede entrenar y buscan intentar encontrar algÃºn tipo de organizaciÃ³n o patrÃ³n en los datos de entrada que recibe. 
Estos algoritmos suelen tener un comportamiento "exploratorio", y en el caso de enfrentar un problema de agrupamiento, estos algoritmos intentan agrupar a los datos por medio de caracterÃ­sticas similares pero no sin saber previamente que tipos de datos va a agrupar. 

Necesita indicaciones previas, No necesita datos previamente etiquetados. Aprende a comprender y a analizar la informaciÃ³n. PrÃ¡ctica sobre los datos que tiene.
Busca relaciones entre los datos - para identificarlos - pero no los podrÃ¡ "etiquetar"

.-. Dimension reduction Reducen las caracteristicas haciendo que la clasificaciÃ³n sea mÃ¡s fÃ¡cil.
.-. Density estimation Se utiliza bÃ¡sicamente para explorar los datos y encontrar alguna estructura interna.
.-. Market basket analysis es una tÃ©cnica de modelado basada en la teorÃ­a de que si se compra cierto producto es mÃ¡s probable que compres otro grupo de articulos.
.-. Clustering is grouping of data points or objects that are somehow similar by Discovering structure, Summarization, Anomaly detection. Usada para agrupar los puntos de datos u objetos similares de algÃºn modo.
segmentaciÃ³n de clientes, agrupamiento de gustos favoritos.

Tiene menos modelos y menos mÃ©todos de evaluaciÃ³n.
Entorno menos controlable, la mÃ¡quina crea resultados para nosotros.


.-. De Refuerzo - Aprendizaje reforzado

Aprende por su cuenta, en base a conocimientos introducidos previamente, aprende en funciÃ³n del Ã©xito Ã³ fracaso.

Las tÃ©cnicas de aprendizaje por refuerzo se basan en modificar la respuesta del algoritmo utilizando un proceso de retroalimentaciÃ³n basado en un conjunto de recompensas y castigos que le permiten al algoritmo identificar cuando alguna de las acciones que realizo previamente obtuvo buenos resultados o fue un comportamiento que deberÃ¡ evitar en futuras ejecuciones. Estas tÃ©cnicas de aprendizaje intentan simular el proceso de aprendizaje humano, simulando la sensaciÃ³n de que el algoritmo aprende obteniendo informaciÃ³n de cÃ³mo se modifica el mundo que lo rodea en respuesta de las acciones que produce.  

La acciÃ³n le puede generar una recompensa y la repites.. si es un castigo lo evitas 

.-. Pasos a seguir para la construcciÃ³n de un mÃ³delo -O-J-O-

Revisar la descripciÃ³n de los datos, utilizando el mÃ©todo describe() like summary on RStudio.
Utilizar la media y la mediana para determinar la tendencia central.
Tener especial atenciÃ³n a los percentiles para poder identificar los rangos de los datos.
Usar una matriz de correlaciÃ³n para identificar las relaciones fuertes en los datos.
Hacer visualizaciones para mejorar tu entendimiento de los datos (Box plot, Density plot, Scatter plot).
Limpiar tus datos (NA, outliers). 
Seleccionar un algorÃ­tmo adecuado para construir un modelo de predicciÃ³n,
Entrenar un modelo para entender los patrones que puede haber dentro de los datos,
Predecir con precisiÃ³n bastante alta en datos nuevos y desconocidos



"""





# CÃ³digo del cÃ¡lculos de los mÃ³delos:
    - MÃ¡quinas de Soporte Vectorial - Support Vector Regression
    - Ãrboles de decisiÃ³n

Regression.py
Classification.py
Clustering.py
ScikitLearn.py
Scipy.py



# BostonDataSet
# =============================================================================
""" 



""" 
  

"""     

"""



# =============================================================================

# 1. -> K vecinos mÃ¡s cercanos - KNN
# 2. -> Ãrboles de decisiÃ³n :  https://web.fdi.ucm.es/posgrado/conferencias/JorgeMartin-slides.pdf
#   CART - Ãrboles de clasificaciÃ³n y regresiÃ³n 
# pretenden explicar o predecir una variable a partir de un conjunto de variables predictoras utilizando un conjunto de reglas sencillas. 
# 3. -> Random Forest -> Bosques Aleatorios
# 4. -> k-medias -> no supervisado, usado para clusterizaciÃ³n
"""


"""
# 2. -> RegresiÃ³n MÃºltiple - Supervisado - Utilizamos regresiÃ³n mÃºltiple cuando estudiamos la posible relaciÃ³n entre varias variables independientes (predictoras o explicativas) y otra variable dependiente (criterio, explicada, respuesta). ... Las modelos de regresiÃ³n nos informan de la presencia de relaciones, pero no del mecanismo causal.
"""
# Multiples variables independientes en el mismo mÃ³delo.
# Importante saber elegir las variables independientes
# =============================================================================
"""
# 3. -> RegresiÃ³n polinomial - Supervisado - 
"""
# Es parecida a la regresiÃ³n lÃ­neal sÃ³lo que extiende la funciÃ³n a un polinomio flexible que se puede curvar si es necesario.. etc. 
# Representa una curva, y graficarÃ¡ el polinomio que mÃ¡s se parezca a las caracterÃ­sticas de los datos.
# Este modelo aÃ±ade curvatura al elevar la variable _x_ a diferentes potencias. De esta manera, se pueden conseguir diferentes funciones que representan y se ajustan mÃ¡s a la distribuciÃ³n de los datos.
# El procedimiento para generar la regresiÃ³n cuadrÃ¡tica utilizando la tÃ©cnica de ajuste de mÃ­nimos cuadrados inicia construyendo un sistema de ecuaciones que son producto de analizar la suma de los cuadrados de los residuos 
# Parabola = Polinomio de grado 2 = XÂ² = potencia mÃ¡s grande - Derivadas parciales - 
# 
# =============================================================================
"""
# 4. -> MÃ¡quinas de Soporte Vectorial -> SVM -> SVR - Supervisado
"""
# Buscan encontrar un hiperplano que separe los puntos compuestos en una categoria de otra. 
# Delimitar con notoriedad cada una de las caracterÃ­sticas de los diferentes conjuntos.
# Las mÃ¡quinas de soporte vectorial buscan encontrar un hiperplano que separe de forma Ã³ptima a los puntos que componen diferentes categorÃ­as unos de los otros. 
# Este tipo de algoritmo suele utilizarse para predecir a que categorÃ­a pertencerÃ¡ un nuevo punto del que no se tenÃ­a informaciÃ³n con anterioridad.
# SVR -> RegresiÃ³n de Soporte Vectorial - Supervisado - SVR
# Support Vector Regression es un algoritmo de regresiÃ³n basado en las mÃ¡quinas de soporte vectorial utilizados para clasificar elementos de diferentes conjuntos. 
# En la siguiente secciÃ³n se explicara cÃ³mo funciona el algoritmo SVR con datos lineales, 
# pero es importante saber que este algoritmo tambiÃ©n funciona para datos no lineales.

# Objetivos: MÃ¡ximizar el margen(las bandas de soporte que rodean a la lÃ­nea de regresiÃ³n) para abarcar la mayorÃ­a de los puntos de nuestro mÃ³delo y Minimizar el error

#     https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR
#     https://scikit-learn.org/stable/modules/svm.html#tips-on-practical-use
# 
# =============================================================================
"""
# 5. -> Ãrboles de decisiÃ³n : NO Supervisado
"""
# https://web.fdi.ucm.es/posgrado/conferencias/JorgeMartin-slides.pdf
# CART - Ãrboles de clasificaciÃ³n (asigna una etiqueta) y regresiÃ³n (asigna una valor) 
# pretenden explicar o predecir una variable a partir de un conjunto de variables predictoras utilizando un conjunto de reglas sencillas. 
# Se hacen diferentes intervalos y a cada uno se asigna un valor de tal forma se podrÃ¡ identificar cada punto a que rango pertenece
# El procedimiento para generar un Ã¡rbol de regresiÃ³n empieza partiendo la totalidad del intervalo de los datos de la variable independiente x en diferentes intervalos pequeÃ±os. En nuestro ejemplo aprovecharemos que es posible identificar que los datos parecen estar agrupados en los siguientes cuatro intervalos:
    
# =============================================================================
#     ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘™ğ‘œ1: 0 â‰¤ ğ‘¥ < 0.25 => ğ‘¦=10
#     ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘™ğ‘œ2: 0.25 â‰¤ ğ‘¥ < 0.5 => ğ‘¦=15
#     ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘™ğ‘œ3: 0.5 â‰¤ ğ‘¥ < 0.75 => ğ‘¦=20
#     ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘™ğ‘œ4: 0.75 â‰¤ ğ‘¥ â‰¤ 1.0 => ğ‘¦=15
#    
#    Asignarle un valor numÃ©rico a una entrada x de la cuÃ¡l no se conocÃ­a su valor de salida y previamente.
# =============================================================================


"""
# 6. -> Redes neuronales => recibir, procesar y transmitir informaciÃ³n
"""
# PerceptrÃ³n => neurona artificial, la uniÃ³n de varios crean una red neuronal artificial. <=> simulan a las humanas y son capaces de transmitir seÃ±ales entre ellas e ir modificando las entradas de las neuronas para obtener valores de salida
# Aprenden a partir de la experiencia para predecir

# Se compone de:
# - Canales/SeÃ±ales de entrada - Dentritas
# - FunciÃ³n de activaciÃ³n - Soma o nÃºcleo - (uniÃ³n sumadora)
# - Canal de salida y AxÃ³n.

"""  n
 Î£ WiXi + b
i=0  """


""" 


# scikit-learn.org/ -- Machine Learning en Python 
# https://scikit-learn.org/stable
""" 
https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets

https://scikit-learn.org/stable/datasets/index.html#boston-dataset
 """





# limpieza de datos
# verificar los null's


# si NULOS => FALSE => NO hay null's

# calculamos el coeficiente de CORrelaciÃ³n
# NO Diagonales => CorrelaciÃ³n â€”> entran escalados entre -1 y 1.
# Si las variables estÃ¡n muy correlacionadas R tendrÃ¡ valor entre -1 y 1.
# Existen dos tipos de correlaciones tanto negativas como positivas
# CorrelaciÃ³n positiva => > 0 , aumenta una variable por tanto aumenta la otra.
# ex: Estatura - Peso - crecen a la vez.
# CorrelaciÃ³n negativa => < 0, aumenta una variable y disminuye la otra.
# ex: Velocidad vs AutonomÃ­a. > aceleraciÃ³n < autonomÃ­a

# Cuando estÃ¡n mÃ¡s cercanos a 1, la nube de puntos va a ser mÃ¡s perfecta a una lÃ­nea.
# si hay alguna correlaciÃ³n que me dÃ© 1.00000000 podemos decir que es una
# correlaciÃ³n perfecta., Ã³ que esas dos variables son la misma variable, independiente de las
# unidades en que este medida.
# correlaciÃ³n baja estÃ¡ entre -0,2 y +0,2
# Valores altos => cercano a -1 Ã³ +1 â€”> en la primera fila y primera columna.
# Valores bajos => cercanos a 0 => resto de elementos entre la segunda fila y la diagonal.
# R: = 0 => Indica que no tienen nada de correlaciÃ³n.
# R: = 1 => CorrelaciÃ³n Perfecta.

# R makes it easy to combine multiple plots into one overall graph, using either the
# par( ) or layout( ) function.

# With the par( ) function, you can include the option mfrow=c(nrows, ncols) to create a matrix of nrows x ncols plots that are filled in by row. mfcol=c(nrows, ncols) fills in the matrix by columns.


# - Cual es la probabilidad de un evento mas desfavorable.
# p-value -> indica si el regresor influye Ã³ no influye en la variable de respuesta.
# p-value: < 2.2e-16 si < 0.05 => indica si el regresor influye , es decir, influye con un 95%.
# Si p-value: < 0.05 Influye
# Si p-value > 0.05 No tenemos evidencia para decir que influye significativamente.


# Una recta de regresiÃ³n debe cumplir:
# Que la distancia entre los puntos a la recta de regresiÃ³n sea mÃ­nima.

# HipÃ³tesis de Partida - Diagnosis
# - Linealidad -> Se DA por supuesta - Las variables siguen una relaciÃ³n lineal.
# - Normalidad -> Se debe comprobar que los residuos siguen una distribuciÃ³n normal
#     La Y para TODAS las X NO sigue una distribuciÃ³n normal.. PERO
#     La variable Y para un determinado valor de X SI sigue una distribuciÃ³n normal.
# - Homocedasticidad -> varianza constante Ã³ variabilidad constante - distribuciÃ³n de probabilidad de idÃ©ntica amplitud para cada variable aleatoria -
    # La nube de puntos tenga un grosor constante.
    # Heterocedastico -> varianza NO es constante Ã³ variabilidad NO constante, a pesar de que la nube de puntos tiene forma lineal la varianza Ã³ dispersiÃ³n va aumentando:
# - Independencia -> Cuando las observaciones en sÃ­ no estÃ¡n relacionadas.



# R-squared: # Somos capaces de explicar el 77% de la variaciÃ³n de G3.

# 2. -> RegresiÃ³n logÃ­stica - Supervisado - Predecir el resultado de una variable categorica en funciÃ³n de otras independientes.
# Modela la probabilidad de que un evento ocurra en funciÃ³n de otros factores, mÃ©todo de clasificaciÃ³n (binaria, 1 Ã³ 0).
# DibujarÃ¡ una curva que nos indicarÃ¡ la tendencia del conjunto de datos, y nos ayudarÃ¡ a predecir en funciÃ³n de un valor X un valor Y.
# Siempre serÃ¡ entre 0 Ã³ 1

# Si resultado >= 0.5 => devuelve 1
# Si resultado < 0.5 => devuelve 0


# Matriz de ConfusiÃ³n => Compara el valor real con el valor de prediccion

# Real vs predicciÃ³n

# SI vs SI => PC => Positivo Correcto
# NO vs NO => NC => Negativo Correcto
# SI vs NO => FP => Falsos Positivos => Error Tipo 1
# NO vs SI => FN => Falsos Negativos => Error Tipo 2

# La precisiÃ³n sirve para saber la probabilidad de acierto en la predicciÃ³n => (PC + NC ) / Total
# La tasa de error sirve para saber la probabilidad de error en la predicciÃ³n => (FP + FN) / Total

# API Command => kaggle kernels pull alexisbcook/titanic-tutorial

# Para limpiar estos datos lo que haremos serÃ¡ sustituir los valores NA de las edades por la media de edad en cada Pclass

# One Way
# creamos una funciÃ³n que reemplace los valores nulls del dataSet por 0, le pasamos la columna edad, y la columna clase
# =============================================================================
# nulos <- function(Age, Pclass) {
#     newAge <- Age
#     for(i in 1:length(Age)){
#         if( is.na(Age[i]) ) { # si es null
#             if(Pclass[i] == 1){
#                 newAge[i] <- 33.00
#             } else if(Pclass[i] == 2){
#                 newAge[i] <- 28.00
#             } else if(Pclass[i] == 3){
#                 newAge[i] <- 18.00
#             }   
#         }        
#     }
#     return(newAge)
# }
# =============================================================================

# =============================================================================
# # Funciones con varios argumentos y aplicar el resultado a una columna
# datos.19$Age <- nulos(datos.19$Age, datos.19$Pclass)
# 
# 
# # Two Way
# # creamos una funciÃ³n que reemplace los valores nulls del dataSet por 0, para poder calcular la media
# 
# factor(datos.19$Pclass)
# 
# nulos <- function(x) {
#     #print(x)
#     if( is.na(x) )
#         {return (0)}
#     else
#         {return (x)}
# }
# 
# =============================================================================


# Three Way - Otra forma de codificar la funciÃ³n..
# creamos una funciÃ³n que reciba la edad y la clase, reemplaza los valores nulls del dataSet por la media que corresponda con la clase:
# =============================================================================
# nulos <- function(x, y) {
#     # x => edad => datos.19$Age
#     # y => class => datos.19$Pclass
#     print(x)
#     print(y)
#     if (y == 1){
#         if( is.na(x) )
#             {return (33)}
#         else
#             {return (x)}
#     } else if (y == 2) {
#             if( is.na(x) )
#                 {return (28)}
#             else
#                 {return (x)}
#     } else if (y == 3) {
#             if( is.na(x) )
#                 {return (18)}
#             else
#                 {return (x)}
#     }
#     else {return (x)}
# }
# 
# =============================================================================


# 1. -> K vecinos mÃ¡s cercanos - KNN => clasificaciÃ³n, estima la probabilidad de que un elemento "x" pertenezca a una clase "C", a partir de la informaciÃ³n proporcionada.

# 2. -> Ãrboles de decisiÃ³n :  https://web.fdi.ucm.es/posgrado/conferencias/JorgeMartin-slides.pdf
# Sirven Representar y Categorizar una serie de condiciones que ocurren de forma sucesiva, para la resoluciÃ³n de un problema.

# 3. -> Random Forest -> Bosques Aleatorios - Algoritmo de clasificaciÃ³n
# combinaciÃ³n entre arboles de decisiÃ³n en la que cada arbol selecciona una clase y luego se combinan las decisiones de cada uno para seleccionar la mejor opciÃ³n.
# Maneja cientos de variables de entrada, eficiente en DB grandes

# 3. -> MÃ¡quinas de Soporte Vectorial -> SVM -> Conjunto de algoritmos de aprendizaje supervisado para resolver problemas de clasificaciÃ³n y regresiÃ³n.
# Analizar datos y resolver patrones
# Dado un conjunto de ejemplos de entrenamiento, podemos etiquetar las clases y entrenar una SVM para construir un mÃ³delo que prediga la clase de una nueva muestra.

# Se separan las clases en dos espacios lo mÃ¡s amplio posible..


# 4. -> k-medias -> no supervisado, usado para clusterizaciÃ³n
# ParticiÃ³n de un conjunto de "n" observaciones en "k" grupos, en el que cada observaciÃ³n pertenece al grupo cuyo valor medio es mÃ¡s cercano. - mineria de datos

# Cross Validation -O-J-O-
# 


""" 
=====================================
Python libraries for Machine Learning
=====================================
NumPy
-----
Biblioteca de matemÃ¡ticas para trabajar con arreglos de n-dimensiones.
(para trabajar con arreglos, diccionarios, funciones, tipos de datos y trabajar con imagenes).

SciPy
-----
Algoritmos nÃºmericos y herramientas de dominio especifico, incluyen procesamiento de seÃ±ales, optimizaciÃ³n, estadistica, computaciÃ³n cientifica de alto rendimiento.

matplotlib
----------
Proporciona 2D plotting and 3D plotting.

pandas
------
estructuras de datos de alto rendimiento fÃ¡ciles de utilizar. ImportaciÃ³n, manipulaciÃ³n y anÃ¡lisis de datos.
en particular manipular tablas nÃºmericas y series de tiempo

scikit-learn - sklearn_library.py
------------
Coleccion de Algoritmos y herramientas para ML.
- Free software ML for Python
- MayorÃ­a de Algoritmos de clasificaciÃ³n, regresiÃ³n y agrupamiento.
- trabajar con Bibliotecas nÃºmericas y cientificas de Python, NumPy, SciPy.
preprocesamiento de datos, seleccion de caracteristicas, extracciÃ³n de caracteristicas, divisiÃ³n de entrenamiento y prueba, definiciÃ³n de Algoritmos, modelos de ajuste, parametros de ajuste, predicciones, evaluaciÃ³n y exportaciÃ³n del modelo.

""" 